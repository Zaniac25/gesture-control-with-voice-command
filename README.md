ğŸ–ï¸ğŸ™ï¸ Hand Gesture & Voice Control System

A powerful Python-based system that allows users to control their computer using hand gestures and voice commands â€” enabling touchless human-computer interaction.

This project uses Computer Vision and Speech Recognition to perform system-level operations like cursor control, clicking, scrolling, volume adjustment, screenshots, and more.

ğŸš€ Features
ğŸ–ï¸ Gesture Controls

Cursor movement using index finger tracking:

Left click / Right click
Double click
Scroll up / Scroll down
Volume control
Screenshot capture
System lock
Smooth cursor movement using EMA (Exponential Moving Average)
Cooldown protection to prevent repeated triggers

ğŸ™ï¸ Voice Controls:

Wake word: "computer"
Short activation window after wake word

Commands like:

Open applications
Volume up/down
Take screenshot
Lock system
Shutdown (optional)
Thread-based voice listener for non-blocking performance

ğŸ›¡ï¸ Safety Features

PyAutoGUI failsafe
Action cooldown timers
Camera warm-up handling
Rotating logs for debugging
Configurable gesture-action mapping
Adjustable sensitivity & smoothing

ğŸ—ï¸ Project Structure
hand_gesture_voice_system/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ gesture_recognition.py
â”‚   â”œâ”€â”€ voice_commands.py
â”‚   â”œâ”€â”€ system_controller.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ gesture_classifier.pkl
â”‚   â””â”€â”€ training_data/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ commands.json
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ basic_demo.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ setup_guide.md

ğŸ§ Technologies Used 

Python
OpenCV
MediaPipe
PyAutoGUI
SpeechRecognition
Threading
JSON Configuration
Logging (RotatingFileHandler)

âš™ï¸ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/yourusername/hand-gesture-voice-control.git
cd hand-gesture-voice-control

2ï¸âƒ£ Create Virtual Environment (Recommended)
python -m venv venv


Activate it:

Windows
venv\Scripts\activate


Mac/Linux
source venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

â–¶ï¸ How to Run
python main.py


Make sure:

Your webcam is connected
Microphone is enabled
Proper permissions are granted

ğŸ¯ Gesture Mapping (Example)
Gesture	Action
1 Finger	Move Cursor
2 Fingers	Left Click
3 Fingers	Right Click
Pinch	Drag
Palm Open	Scroll
Fist	Lock System
(Mappings can be modified in commands.json)

ğŸ™ï¸ Voice Command Flow

Say "computer"
System activates listening window
Speak command within activation time

Example:

computer open chrome
computer volume up
computer take screenshot

ğŸ”§ Configuration

All customizable parameters are inside:

config/settings.py
config/commands.json


You can modify:

Cursor sensitivity
Smoothing factor
Cooldown time
Wake word
Gesture-to-action mapping
Voice commands

ğŸ“Š System Architecture

Camera captures frames
MediaPipe detects hand landmarks
Gesture recognition logic processes landmarks
Action mapped to system_controller
Voice thread listens for wake word
Recognized command triggers system action
Both gesture and voice modules run efficiently without blocking the main loop.

ğŸ› ï¸ Future Improvements

Multi-hand recognition
Custom gesture training UI
GUI dashboard
Cross-platform optimization
AI-based dynamic gesture learning
Integration with IoT devices

ğŸ“¸ Demo (Add Screenshots Here)

You can add:
Running application screenshot
Hand landmark detection
HUD display
Voice activation message

ğŸ“Œ Use Cases

Accessibility support
Touchless interaction
Smart classrooms
Presentations
Automation enthusiasts
Smart home integration

ğŸ§ª Requirements

Python 3.8+
Webcam
Microphone
Windows/Linux/Mac

ğŸ‘¨â€ğŸ’» Author

zaniac25
B.Tech CSE | AI/ML Enthusiast | Computer Vision Developer

â­ If You Like This Project
Give it a â­ on GitHub and feel free to contribute!